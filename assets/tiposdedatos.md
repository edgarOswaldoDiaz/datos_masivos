#### Big Data

El Big Data es un término que describe el gran volumen de datos, tanto estructurados como no estructurados, que se generan y recopilan a diario. Estos datos pueden provenir de una variedad de fuentes, como redes sociales, sensores, dispositivos móviles, transacciones comerciales y registros gubernamentales.

Algunos ejemplos de cómo se utiliza el Big Data en la práctica incluyen:

- Marketing: Las empresas utilizan el Big Data para segmentar a los clientes, personalizar las ofertas y medir el rendimiento de las campañas de marketing.
- Ventas: Las empresas utilizan el Big Data para predecir la demanda de productos, optimizar las rutas de entrega y mejorar la atención al cliente.
- Fabricación: Las empresas utilizan el Big Data para mejorar la eficiencia de la producción, reducir los costes y prevenir los defectos.
- Salud: Las empresas utilizan el Big Data para desarrollar nuevos tratamientos, mejorar la atención al paciente y prevenir las enfermedades.
- Gobierno: Los gobiernos utilizan el Big Data para mejorar la seguridad pública, la planificación urbana y la prestación de servicios públicos.

#### Las 6V´s del Big Data (Grandes volúmenes de datos)

- Volumen: Se refiere a la cantidad masiva de datos generados, recopilados y almacenados. Con Big Data, las organizaciones manejan conjuntos de datos que pueden variar desde gigabytes hasta terabytes o incluso petabytes.
- Variedad: Indica la diversidad de tipos de datos. Big Data no se trata solo de datos estructurados (como bases de datos tradicionales), sino también de datos no estructurados y semiestructurados, como texto, imágenes, videos, sonidos, registros de redes sociales, etc.
- Velocidad: Hace referencia a la velocidad a la que se generan, procesan y deben utilizarse los datos. En algunos casos, como en aplicaciones de transmisión en vivo, la velocidad de procesamiento de datos es crítica.
- Veracidad: Se relaciona con la calidad y confiabilidad de los datos. En un entorno de Big Data, los datos pueden provenir de diversas fuentes con diferentes grados de precisión y confiabilidad, por lo que es esencial garantizar la veracidad de los datos.
- Valor: Es la capacidad de convertir los datos en información valiosa y, finalmente, en conocimiento para la toma de decisiones. El objetivo último de trabajar con Big Data es obtener información significativa que agregue valor a una organización.
- Viabilidad: Algunas fuentes añaden la "viabilidad" como una sexta V, refiriéndose a la necesidad de evaluar la viabilidad económica y técnica de manejar y procesar grandes volúmenes de datos. Esto incluye considerar la infraestructura necesaria, los costos asociados y la capacidad para gestionar eficientemente los recursos.

#### Que es la ciencia de datos

La ciencia de datos es un campo interdisciplinario que utiliza métodos, procesos, algoritmos y sistemas científicos para extraer conocimiento y penetrar en la comprensión de fenómenos complejos. Combina elementos de estadísticas, matemáticas y ciencias de la computación para analizar y comprender datos. 

El proceso típico de ciencia de datos implica la recopilación, limpieza, análisis y visualización de datos para obtener información significativa y tomar decisiones informadas.

- Recopilación de datos: Implica la adquisición de datos de diversas fuentes, que pueden ser estructurados (como bases de datos) o no estructurados (como texto o imágenes).
- Preprocesamiento de datos: Incluye la limpieza y transformación de datos para eliminar errores, valores atípicos o información innecesaria, y para preparar los datos para su análisis.
- Análisis de datos: Aplica técnicas estadísticas, algoritmos de aprendizaje automático y otros métodos para descubrir patrones, relaciones y tendencias en los datos.
- Machine Learning: Es una rama de la ciencia de datos que se centra en el desarrollo de algoritmos y modelos que permiten a las computadoras aprender de los datos y realizar tareas específicas sin ser programadas explícitamente.
- Visualización de datos: Utiliza gráficos y visualizaciones para representar de manera efectiva la información descubierta durante el análisis, facilitando la interpretación y la toma de decisiones.
- Big Data: Se refiere al manejo y análisis de conjuntos de datos extremadamente grandes y complejos que no pueden ser procesados con herramientas tradicionales de bases de datos.
- Inteligencia Artificial (IA): A menudo se entrelaza con la ciencia de datos, ya que la IA utiliza técnicas de aprendizaje automático para permitir a las máquinas realizar tareas que normalmente requieren inteligencia humana.

#### Relación de la ciencia de datos con big data

Proceso de Datos

- Big Data: Se refiere a conjuntos de datos extremadamente grandes que superan la capacidad de las herramientas de procesamiento de datos convencionales. Esto puede incluir datos estructurados, no estructurados y semiestructurados. Las tecnologías de big data como Hadoop y Spark se utilizan para gestionar, almacenar y procesar estos volúmenes masivos de datos.
- Ciencia de Datos: Implica el uso de técnicas avanzadas de análisis de datos, estadísticas y aprendizaje automático para extraer conocimientos y patrones significativos de los datos. La ciencia de datos puede aprovechar las capacidades de procesamiento de big data para analizar grandes cantidades de información y descubrir relaciones complejas.

Herramientas y Tecnologías

- Big Data: Implica el uso de tecnologías específicas para gestionar y procesar grandes cantidades de datos. Esto puede incluir sistemas de almacenamiento distribuido, bases de datos NoSQL, y marcos de procesamiento paralelo como Apache Hadoop y Apache Spark.
- Ciencia de Datos: Utiliza herramientas y técnicas para analizar datos y extraer información. Esto puede incluir lenguajes de programación como Python y R, bibliotecas como Pandas y scikit-learn, y entornos de desarrollo integrados (IDE) como Jupyter.

Escalabilidad

- Big Data: Se centra en la escalabilidad para manejar volúmenes masivos de datos y asegurar un rendimiento eficiente incluso cuando se trabaja con petabytes de información.
- Ciencia de Datos: Puede aprovechar la escalabilidad proporcionada por las tecnologías de big data para analizar conjuntos de datos a gran escala y realizar modelos más complejos y precisos.

Extracción de Valor

- Big Data: Proporciona la infraestructura necesaria para almacenar y procesar grandes cantidades de datos, pero no necesariamente realiza análisis detallados o modelado predictivo por sí mismo.
- Ciencia de Datos: Se centra en extraer información significativa de los datos, identificando patrones, construyendo modelos predictivos y proporcionando conocimientos accionables para la toma de decisiones.


Nota: el big data proporciona la infraestructura para gestionar grandes volúmenes de datos, mientras que la ciencia de datos se centra en extraer conocimientos valiosos de esos datos. Juntas, estas disciplinas permiten abordar problemas complejos y tomar decisiones informadas basadas en datos a gran escala.

Datos estructurados

En el contexto de Big Data, los datos estructurados se refieren a la información organizada de manera formal y predefinida, que se presenta en un formato tabular con filas y columnas. Estos datos están altamente organizados y son fáciles de almacenar, procesar y analizar. A menudo se representan en bases de datos relacionales y se pueden manipular utilizando consultas SQL.

Las características clave de los datos estructurados incluyen:

- Formato Tabular: Los datos están organizados en tablas con filas y columnas, donde cada columna tiene un nombre y un tipo de dato específico.
- Esquema Definido: Existe un esquema predefinido que describe la estructura de los datos, especificando qué tipo de datos se almacenan en cada columna.
- Facilidad de Consulta: Se pueden realizar consultas mediante lenguajes como SQL para extraer información específica de la base de datos.

Datos no estructurados

Los datos no estructurados en el contexto del big data se refieren a información que no sigue un formato predefinido o no está organizada de manera tabular. A diferencia de los datos estructurados, que se almacenan en bases de datos relacionales y se presentan en filas y columnas, los datos no estructurados no tienen un formato uniforme y pueden incluir diversos tipos de información, como texto sin formato, imágenes, audio, video, mensajes de redes sociales, correos electrónicos, entre otros.

Algunos ejemplos de datos no estructurados incluyen:

- Texto sin formato: Documentos, informes, blogs, artículos, correos electrónicos, entre otros.
- Imágenes: Fotografías, gráficos, mapas, escaneos, entre otros.
- Audio: Archivos de sonido, grabaciones, llamadas telefónicas, entre otros.
- Video: Grabaciones de video, transmisiones en vivo, clips, entre otros.
- Datos de redes sociales: Mensajes, comentarios, tweets, publicaciones, entre otros.

Tipos de formatos de datos estructurados en big data 

- CSV (Comma-Separated Values): Este formato utiliza comas para separar los valores en cada fila, y las filas representan registros. Es simple y fácil de entender, pero puede no ser eficiente para conjuntos de datos muy grandes.

- JSON (JavaScript Object Notation): Es un formato de intercambio de datos ligero y fácil de leer que utiliza pares de clave-valor. Es comúnmente utilizado en aplicaciones web y es fácilmente parseable por muchas tecnologías.

- XML (eXtensible Markup Language): Similar a JSON, XML es un formato de marcado que utiliza etiquetas para estructurar la información. Es más verboso que JSON y ha sido ampliamente utilizado en la web y en integraciones de sistemas.

- Avro: Es un formato de serialización binaria desarrollado dentro del proyecto Apache Hadoop. Avro es compacto, eficiente y permite la evolución de esquemas, lo que lo hace adecuado para sistemas Big Data.

- Parquet: Un formato de almacenamiento columnar que está diseñado para ser eficiente en términos de almacenamiento y procesamiento. Parquet es ampliamente utilizado en entornos de Big Data, especialmente con herramientas como Apache Spark y Apache Hive.

- ORC (Optimized Row Columnar): Similar a Parquet, es otro formato de almacenamiento columnar que se utiliza para mejorar el rendimiento en entornos Big Data, especialmente con tecnologías como Apache Hive.

- Apache Arrow: Es una plataforma de procesamiento de datos en memoria que también define un formato de intercambio de datos columnar. Arrow se utiliza para facilitar la transferencia eficiente de datos entre diferentes sistemas.

- HDF5 (Hierarchical Data Format version 5): Es un formato de archivo y conjunto de herramientas para gestionar datos complejos. Aunque no es exclusivo de Big Data, se utiliza en este contexto para almacenar grandes conjuntos de datos científicos y de otro tipo.

- Protocol Buffers (protobuf): Un formato de serialización binaria desarrollado por Google. Es eficiente en términos de tamaño y se utiliza en diversas aplicaciones, incluidas aquellas en el ámbito de Big Data.

Tipos de formatos de datos “no estructurados” en big data 

- Texto sin formato (Plain Text): Datos en forma de texto simple, como documentos, correos electrónicos, tweets o cualquier otro contenido de texto sin una estructura rígida.

- Datos de registro (Log Files): Archivos que registran eventos y actividades de sistemas, aplicaciones o servicios. Estos archivos pueden contener información diversa y suelen seguir un formato de texto.

- Imágenes: Datos visuales en forma de imágenes, fotos o gráficos. Estos datos pueden almacenarse en formatos como JPEG, PNG, GIF, entre otros.

- Audio y Vídeo: Datos en forma de archivos de audio o video. Los formatos comunes incluyen MP3, WAV para audio, y MP4, AVI para video.

- Documentos Binarios: Archivos binarios que no siguen una estructura de texto, como documentos de Ofimática, archivos PDF, entre otros.

- Datos de Redes Sociales: Información recopilada de plataformas de redes sociales, que pueden incluir texto, imágenes, videos, enlaces y otros tipos de contenido.

- Datos de Sensores y Dispositivos IoT: Datos generados por sensores y dispositivos conectados a Internet de las Cosas (IoT). Estos datos pueden ser variados y no seguir una estructura específica.

- Datos Geoespaciales: Información relacionada con la ubicación, como coordenadas geográficas, mapas y datos de geolocalización.

- Secuencias de ADN: En el ámbito de la bioinformática, los datos genéticos pueden representarse en forma de secuencias de ADN, que son datos no estructurados y complejos.

- Flujos de Datos en Tiempo Real: Datos que llegan continuamente y en tiempo real, como transmisiones de eventos en redes sociales, registros de servidores en tiempo real, etc.

- Correo Electrónico: Los mensajes de correo electrónico, que pueden contener texto, archivos adjuntos y otros elementos multimedia.

Nota: La gestión de datos no estructurados en entornos de Big Data puede ser un desafío debido a su diversidad y complejidad. Herramientas y plataformas, como Apache Hadoop y Apache Spark, se utilizan para procesar y analizar datos no estructurados en conjunción con datos estructurados.

_______________________
Referencias
> Lalaoui, I. L., El Haji, E., & Kounaidi, M. (2025). *The evolution and challenges of real-time big data: A review*. *Computer Sciences & Mathematics Forum, 10*(1), 11. 

> Gonçalves, S., Ventura, J. B., Rua, O. L., Dias, R., & Galvão, R. (2024). *Big data como paradigma emergente en la gestión de las organizaciones: Un análisis bibliométrico*. *Journal of Ecohumanism, 3*(7), 2699–2721. 

> Chen, C. T., Khan, A., & Chen, S. C. (2024). *Modelado del impacto de Big Data Analytics (BDA) y AI en la innovación sostenible, la ambidextría y el desempeño ambiental*. *Journal of Big Data, 11*, 124. 

> Chen, J., Zhang, C., & Zhou, J. (2021). *Big data integration in business intelligence: A survey*. *Journal of Business Research, 124*, 14–25. 

> Hakami, T. A. (2025). *Exploring the evolution of Big Data technologies*. *MDPI*, *Future Internet, 17*(9), 427. 


















